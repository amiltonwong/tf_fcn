{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import sys\n",
    "from random import shuffle\n",
    "from random import uniform\n",
    "import zipfile\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "import time\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_train_path = '/data2/cityscapes_dataset/gtFine/train'\n",
    "imgs_train_path = '/data2/cityscapes_dataset/leftImg8bit/train'\n",
    "gt_val_path = '/data2/cityscapes_dataset/gtFine/val'\n",
    "imgs_val_path = '/data2/cityscapes_dataset/leftImg8bit/val'\n",
    "gt_test_path = '/data2/cityscapes_dataset/gtFine/test'\n",
    "imgs_test_path = '/data2/cityscapes_dataset/leftImg8bit/test'\n",
    "\n",
    "# Get filenames of training data and gt, specific for cityscapes dataset\n",
    "def get_files(imgs_dir, gt_dir):\n",
    "    \n",
    "    cities = os.listdir(imgs_dir)\n",
    "    gt = []\n",
    "    imgs = []\n",
    "    for city in cities:\n",
    "        new_gt_path = os.path.join(gt_dir, city)\n",
    "        new_imgs_path = os.path.join(imgs_dir, city)\n",
    "        gt += glob.glob(os.path.join(new_gt_path, \"*labelIds.png\"))\n",
    "        imgs += glob.glob(os.path.join(new_imgs_path, \"*.png\"))\n",
    "    imgs.sort()\n",
    "    gt.sort()\n",
    "    return imgs, gt\n",
    "\n",
    "# Get filenames of training data and gt\n",
    "train_imgs, train_gt = get_files(imgs_train_path, gt_train_path)\n",
    "val_imgs, val_gt = get_files(imgs_val_path, gt_val_path)\n",
    "test_imgs, test_gt = get_files(imgs_test_path, gt_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_image(image_path=None, img=None, from_path=True):\n",
    "    if (from_path == True):\n",
    "        img = misc.imread(image_path)\n",
    "    if len(img.shape) == 4:\n",
    "        img = np.squeeze(img)\n",
    "    if img.dtype != np.uint8:\n",
    "        img = img.astype(np.uint8)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_ground_truth for cityscape data\n",
    "def prepare_ground_truth(img):\n",
    "    \n",
    "    # Five classes: road, side_walk, pedestrian, vehicles, others\n",
    "    NUM_CLASSES = 5\n",
    "    new_image = np.zeros((img.shape[0], img.shape[1], NUM_CLASSES))\n",
    "    \n",
    "    # (original_id)\n",
    "    # road\n",
    "    road_mask = img == 7\n",
    "    # sidewalk \n",
    "    side_mask = img == 8\n",
    "    # pedestrians[person,rider]\n",
    "    ped_mask = np.logical_or(img == 24, img == 25)\n",
    "    # vehicles[car,truck,bus,caravan,trailer,train,motorcycle, bicycle, license plate]\n",
    "    car_mask = np.logical_or.reduce((img == 26, img == 27, img == 28,\n",
    "                                      img == 29, img == 30, img == 31,\n",
    "                                      img == 32, img == 33, img == -1))\n",
    "    # everything else\n",
    "    else_mask = np.logical_not(np.logical_or.reduce((road_mask, side_mask,\n",
    "                                                     ped_mask, car_mask)))\n",
    "    \n",
    "    new_image[:,:,0] = road_mask\n",
    "    new_image[:,:,1] = side_mask\n",
    "    new_image[:,:,2] = ped_mask\n",
    "    new_image[:,:,3] = car_mask\n",
    "    new_image[:,:,4] = else_mask\n",
    "    \n",
    "    return new_image.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num_classes = 20, 19 objects classes plus one background glass\n",
    "def prepare_ground_truth_normal(img):\n",
    "    \n",
    "    # Five classes: road, side_walk, pedestrian, vehicles, others\n",
    "    NUM_CLASSES = 20\n",
    "    new_image = np.zeros((img.shape[0], img.shape[1], NUM_CLASSES))\n",
    "    \n",
    "    # (original_id)\n",
    "    # road\n",
    "    road_mask = img == 7\n",
    "    # sidewalk \n",
    "    side_mask = img == 8\n",
    "    # pedestrians[person,rider]\n",
    "    ped_mask = np.logical_or(img == 24, img == 25)\n",
    "    # vehicles[car,truck,bus,caravan,trailer,train,motorcycle, bicycle, license plate]\n",
    "    car_mask = np.logical_or.reduce((img == 26, img == 27, img == 28,\n",
    "                                      img == 29, img == 30, img == 31,\n",
    "                                      img == 32, img == 33, img == -1))\n",
    "    # everything else\n",
    "    else_mask = np.logical_not(np.logical_or.reduce((road_mask, side_mask,\n",
    "                                                     ped_mask, car_mask)))\n",
    "    \n",
    "    new_image[:,:,0] = road_mask\n",
    "    new_image[:,:,1] = sidewalk_mask\n",
    "    new_image[:,:,2] = building_mask\n",
    "    new_image[:,:,3] = wall_mask\n",
    "    new_image[:,:,4] = fence_mask\n",
    "    new_image[:,:,5] = pole_mask\n",
    "    new_image[:,:,6] = traffic_light_mask\n",
    "    new_image[:,:,7] = traffic_sign_mask\n",
    "    new_image[:,:,8] = vegetation_mask\n",
    "    new_image[:,:,9] = terrain_mask\n",
    "    new_image[:,:,10] = sky_mask\n",
    "    new_image[:,:,11] = person_mask\n",
    "    new_image[:,:,12] = rider_mask\n",
    "    new_image[:,:,13] = car_mask\n",
    "    new_image[:,:,14] = truck_mask\n",
    "    new_image[:,:,15] = bus_mask\n",
    "    new_image[:,:,16] = train_mask\n",
    "    new_image[:,:,17] = motorcycle_mask\n",
    "    new_image[:,:,18] = bicycle_mask\n",
    "    new_image[:,:,19] = else_mask\n",
    "    \n",
    "    return new_image.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define FCN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
